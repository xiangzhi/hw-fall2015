One of the active research area in Human-Robot Interaction is the communication of intend between the robot and human user. Direct communication in this area are often done through voice commands or input devices such as keyboards and touch based interfaces mounted on the robot. Instead of relying on external system or additional hardware, we looked into how we could use an existing hardware on the robot, it's manipulator arm as an input devices.\\
One of the benefits of using the robot's arm is that we do not need to add additional hardware on the system. Furthermore, our method is less susceptible to factors in the environment like noises or light that might effect voice commands and computer vision techniques since our method relies on a direct physical connection that would not be influence by the surrounding.\\
As far as we know, none of the manipulators are designed with such functionality in mind nor systems been created to use existing arms as input device. Therefore, we designed a proof-of-concept system that shows it is possible to detect and classify user's intent through detecting different movement of the robot's arm by the user. Our system emulates how a normal joystick works in the real life and classifies the motions in high level gesture inspired action units like left, right, down and etc. In the following sections, we will describe the system design and preliminary test of the system.